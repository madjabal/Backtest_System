{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 359 ms, sys: 11 ms, total: 370 ms\n",
      "Wall time: 529 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from time import sleep, time\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to maintain and call the S&P 500 from a current date\n",
    "# Author Michael Djaballah\n",
    "# Time last edited: 5:56 PM June 1, 2020\n",
    "# Last edited by: Michael Djaballah\n",
    "\n",
    "# Takes no input\n",
    "# Output is newly saved CSV's containing the current makeup of the S&P 500 \n",
    "# and its historical additions and removals\n",
    "# data_path is changeable depending on desired save location\n",
    "def get_snp_store(data_path='data/'):\n",
    "    curr_raw = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    \n",
    "    curr = curr_raw[0]\n",
    "    hist = curr_raw[1]\n",
    "    \n",
    "    new_hist = pd.DataFrame(hist['Date'])\n",
    "    new_hist['Added'] = hist['Added', 'Ticker']\n",
    "    new_hist['Removed'] = hist['Removed', 'Ticker']\n",
    "    \n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    \n",
    "    curr.to_csv(data_path + 'snp_current.csv', index=False)\n",
    "    new_hist.to_csv(data_path + 'snp_hist.csv', index=False)\n",
    "    return None\n",
    "\n",
    "\n",
    "# Input: a date in string form with its corresponding format:\n",
    "# Ex: 'January 1, 2020', '%B %d, %Y'\n",
    "# Output: a list containing the S&P 500 at the input date\n",
    "def build_snp(date, date_format, data_path='data/'):\n",
    "    curr = pd.read_csv(data_path + 'snp_current.csv')\n",
    "    hist = pd.read_csv(data_path + 'snp_hist.csv')\n",
    "    \n",
    "    start_date = datetime.strptime(date, date_format)\n",
    "    \n",
    "    snp_set = set(curr['Symbol'])\n",
    "    \n",
    "    for i in range(len(hist)):\n",
    "        temp_date = datetime.strptime(hist.iloc[i]['Date'], date_format)\n",
    "        if temp_date < start_date:\n",
    "            break\n",
    "\n",
    "        tb_removed = hist.iloc[i]['Added']\n",
    "        tb_added = hist.iloc[i]['Removed']\n",
    "\n",
    "        if tb_removed in snp_set:\n",
    "            snp_set.remove(tb_removed)\n",
    "        if not type(tb_added) == float:\n",
    "            snp_set.add(tb_added)\n",
    "    \n",
    "    return list(snp_set)\n",
    "\n",
    "# Included to build returns for a SPY comparison\n",
    "# Input is a portfolio (ticker:df dictionary), the tickers desired for returns, and the date of returns\n",
    "# Output is a list of floats that are returns\n",
    "def build_returns(portfolio, tickers, date):\n",
    "    returns = []\n",
    "    for ticker in tickers:\n",
    "        temp_ticker_dict = portfolio[ticker].set_index('Date').loc[date]\n",
    "        returns.append((temp_ticker_dict['Close'] - temp_ticker_dict['Open'])/temp_ticker_dict['Open'])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Portfolio:\n",
    "    def __init__(self, tickers, hist_depth=None, train_depth=None, features=[], \n",
    "                 data_path = 'data/', prefix = 'monthly/', interval = '1mo', \n",
    "                 data_start = '2001-01-01', target='Close'):\n",
    "        self.portfolio = {}\n",
    "        self.tickers = tickers\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        \n",
    "        self.hist_depth = hist_depth\n",
    "        self.train_depth = train_depth\n",
    "        \n",
    "        self.interval = interval\n",
    "        self.data_start = data_start\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.prefix = prefix\n",
    "        \n",
    "        self.results = []\n",
    "        \n",
    "        self.blacklist = set()\n",
    "        \n",
    "        self.portfolio = self.build_portfolio()\n",
    "        self.tickers = list(self.portfolio.keys())\n",
    "        self.columns = self.build_columns()\n",
    "        \n",
    "    \n",
    "    def get_data(self, return_bad_tickers=False):\n",
    "        bad_tickers = []\n",
    "\n",
    "        os.makedirs(self.data_path + self.prefix, exist_ok=True)\n",
    "\n",
    "        curr_tickers = set(os.listdir(self.data_path + self.prefix))\n",
    "\n",
    "        for ticker in self.tickers:\n",
    "            ticker_label = ticker + '.csv'\n",
    "\n",
    "            if ticker_label not in curr_tickers:\n",
    "                temp_ticker = yf.Ticker(ticker)\n",
    "                temp_hist = temp_ticker.history(start=self.data_start, interval=self.interval)\n",
    "                temp_hist.dropna(axis=0, inplace=True)\n",
    "                temp_hist.to_csv(self.data_path + self.prefix + ticker_label)\n",
    "\n",
    "                if len(temp_hist) < 90:\n",
    "                    bad_tickers.append((ticker, len(temp_hist)))\n",
    "                sleep(.5)\n",
    "\n",
    "        if return_bad_tickers:\n",
    "            return bad_tickers\n",
    "\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def build_columns(self):\n",
    "        columns = []\n",
    "        for i in range(self.hist_depth):\n",
    "            for feature in self.features:\n",
    "                columns.append(feature + ' ' + str(i + 1))\n",
    "        return columns\n",
    "    \n",
    "    \n",
    "    def check_ticker(self, ticker, offset):\n",
    "        ticker_df = pd.read_csv(self.data_path + self.prefix + ticker + '.csv')\n",
    "        if len(ticker_df) >= offset:\n",
    "            return ticker_df\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    def build_portfolio(self):\n",
    "        offset = self.train_depth + self.hist_depth + 60 + 6\n",
    "\n",
    "        self.get_data()\n",
    "\n",
    "        ticker_dict = {}\n",
    "\n",
    "        for ticker in self.tickers:\n",
    "            if ticker not in self.blacklist:\n",
    "                ticker_df = self.check_ticker(ticker, offset)\n",
    "                if type(ticker_df) != bool:\n",
    "                    ticker_dict[ticker] = ticker_df\n",
    "\n",
    "        return ticker_dict\n",
    "    \n",
    "    \n",
    "    def build_returns(self, symbols, date):\n",
    "        returns = []\n",
    "        for ticker in symbols:\n",
    "            temp_ticker_dict = self.portfolio[ticker].set_index('Date').loc[date]\n",
    "            returns.append((temp_ticker_dict['Close'] - temp_ticker_dict['Open'])/temp_ticker_dict['Open'])\n",
    "        return returns\n",
    "    \n",
    "    \n",
    "    def build_scaled_df(self, dataframe):\n",
    "        scaler = StandardScaler()\n",
    "        scaled_array = scaler.fit_transform(dataframe)\n",
    "        scaled_dataframe = pd.DataFrame(scaled_array, columns=dataframe.columns)\n",
    "        return scaled_dataframe\n",
    "    \n",
    "    \n",
    "    def check_date(self, ticker, date):\n",
    "        dates = set(self.portfolio[ticker]['Date'])\n",
    "        return date in dates\n",
    "    \n",
    "    \n",
    "    def build_machine(self, model, date, n=15):\n",
    "        train_df = self.build_train_df(date)\n",
    "        scaled_train_df = self.build_scaled_df(train_df)\n",
    "\n",
    "        scaled_train_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "        X = scaled_train_df.values[:,:-1]\n",
    "        y = scaled_train_df.values[:, -1]\n",
    "        model.fit(X, y)\n",
    "\n",
    "        test_df, symbols = self.build_test_df(date)\n",
    "        scaled_test_df = self.build_scaled_df(test_df)\n",
    "        X_test = scaled_test_df.values\n",
    "\n",
    "        predicted_returns = list(model.predict(X))\n",
    "\n",
    "        returns_dict = {}\n",
    "\n",
    "        for i in range(len(symbols)):\n",
    "            returns_dict[symbols[i]] = predicted_returns[i]\n",
    "\n",
    "        top = sorted(returns_dict.items(), key=lambda x: x[1])[::-1][:n]\n",
    "        return [x[0] for x in top]\n",
    "    \n",
    "    \n",
    "    def backtest(self, model, start_date, end_date):\n",
    "        months = list(pd.date_range(start_date, end_date, freq='MS').strftime('%Y-%m-%d'))\n",
    "\n",
    "        overall_returns = []\n",
    "        specific_returns = []\n",
    "        for month in months:\n",
    "            start_time = time()\n",
    "            for ticker in self.tickers:\n",
    "                if ticker not in self.blacklist:\n",
    "                    if not self.check_date(ticker, month):\n",
    "                        self.blacklist.add(ticker)\n",
    "            symbols = self.build_machine(model, month)\n",
    "            ticker_returns = self.build_returns(symbols, month)\n",
    "            overall_returns.append(sum(ticker_returns)/len(ticker_returns))\n",
    "            print(month, round(sum(ticker_returns)/len(ticker_returns), 6), round(time()-start_time, 2))\n",
    "            \n",
    "            specific_returns_dict = {}\n",
    "            for i in range(len(ticker_returns)):\n",
    "                specific_returns_dict[symbols[i]] = ticker_returns[i]\n",
    "            specific_returns.append(specific_returns_dict)\n",
    "            \n",
    "        self.results = specific_returns\n",
    "        return overall_returns\n",
    "    \n",
    "    \n",
    "#     def build_feature_vector(self, ticker, date, keep_pred=True):\n",
    "#         ticker_df = self.portfolio[ticker]\n",
    "\n",
    "#         start_date_dt = datetime.strptime(date, '%Y-%m-%d') - relativedelta(months=self.hist_depth)\n",
    "#         start_date = start_date_dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#         feature_df = ticker_df.set_index('Date')[start_date:date].reset_index(drop=True)[self.features]\n",
    "        \n",
    "#         new_df_dict = {}\n",
    "\n",
    "#         for i in range(len(feature_df)):\n",
    "#             for col in feature_df.columns:\n",
    "#                 if i < len(feature_df) - 1:\n",
    "#                     new_df_dict[col + ' ' + str(i + 1)] = [feature_df[col].iloc[i]]\n",
    "#                 elif col == self.target:\n",
    "#                     if keep_pred:\n",
    "#                         new_df_dict['Target'] = [feature_df[col].iloc[i]]\n",
    "\n",
    "#         new_df = pd.DataFrame.from_dict(new_df_dict)\n",
    "        \n",
    "#         if len(new_df) == 0:\n",
    "#             self.blacklist.add(ticker)\n",
    "#             return -1\n",
    "\n",
    "#         if keep_pred:\n",
    "#             new_df = new_df[[col for col in list(new_df.columns) if col not in {'Target'}] + ['Target']]\n",
    "        \n",
    "#         return new_df\n",
    "    \n",
    "    \n",
    "#     def build_train_df(self, date):    \n",
    "#         vector_list = []\n",
    "#         for ticker in self.tickers:\n",
    "#             if ticker not in self.blacklist:\n",
    "#                 for i in range(self.train_depth):\n",
    "#                     train_start_dt = datetime.strptime(date, '%Y-%m-%d') - relativedelta(months=(1+i))\n",
    "#                     train_start = train_start_dt.strftime('%Y-%m-%d')\n",
    "#                     vector = self.build_feature_vector(ticker, train_start)\n",
    "                    \n",
    "#                     if type(vector) != int:\n",
    "#                         vector_list.append(vector)\n",
    "        \n",
    "#         start_time = time()\n",
    "#         feature_df = pd.concat(vector_list)\n",
    "#         print(time() - start_time)\n",
    "#         return feature_df.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "#     def build_test_df(self, date):\n",
    "#         vector_list = []\n",
    "#         index_list = []\n",
    "#         for ticker in self.tickers:\n",
    "#             if ticker not in self.blacklist:\n",
    "#                 vector = self.build_feature_vector(ticker, date, keep_pred=False)\n",
    "#                 if type(vector) != int:\n",
    "#                     vector_list.append(vector)\n",
    "#                     index_list.append(ticker)\n",
    "\n",
    "#         start_time = time()\n",
    "#         test_df = pd.concat(vector_list)\n",
    "#         print(time() - start_time)\n",
    "#         return test_df.reset_index(drop=True), index_list\n",
    "    \n",
    "    \n",
    "    def build_feature_vector(self, ticker, date, keep_pred=True):\n",
    "        ticker_df = self.portfolio[ticker]\n",
    "\n",
    "        start_date_dt = datetime.strptime(date, '%Y-%m-%d') - relativedelta(months=self.hist_depth)\n",
    "        start_date = start_date_dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        feature_df = ticker_df.set_index('Date')[start_date:date].reset_index(drop=True)[self.features]\n",
    "        \n",
    "        new_df_dict = {}\n",
    "\n",
    "        for i in range(len(feature_df)):\n",
    "            for col in feature_df.columns:\n",
    "                if i < len(feature_df) - 1:\n",
    "                    new_df_dict[col + ' ' + str(i + 1)] = [feature_df[col].iloc[i]]\n",
    "                elif col == self.target:\n",
    "                    if keep_pred:\n",
    "                        new_df_dict['Target'] = [feature_df[col].iloc[i]]\n",
    "\n",
    "        new_df = pd.DataFrame.from_dict(new_df_dict)\n",
    "        \n",
    "        if len(new_df) == 0:\n",
    "            self.blacklist.add(ticker)\n",
    "            return -1\n",
    "\n",
    "        if keep_pred:\n",
    "            new_df = new_df[[col for col in list(new_df.columns) if col not in {'Target'}] + ['Target']]\n",
    "        \n",
    "        return new_df\n",
    "    \n",
    "    \n",
    "    def build_train_df(self, date):    \n",
    "        vector_list = []\n",
    "        for ticker in self.tickers:\n",
    "            if ticker not in self.blacklist:\n",
    "                for i in range(self.train_depth):\n",
    "                    train_start_dt = datetime.strptime(date, '%Y-%m-%d') - relativedelta(months=(1+i))\n",
    "                    train_start = train_start_dt.strftime('%Y-%m-%d')\n",
    "                    vector = self.build_feature_vector(ticker, train_start)\n",
    "                    \n",
    "                    if type(vector) != int:\n",
    "                        vector_list.append(vector)\n",
    "        \n",
    "        start_time = time()\n",
    "        feature_df = pd.concat(vector_list)\n",
    "        print(time() - start_time)\n",
    "        return feature_df.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    def build_test_df(self, date):\n",
    "        vector_list = []\n",
    "        index_list = []\n",
    "        for ticker in self.tickers:\n",
    "            if ticker not in self.blacklist:\n",
    "                vector = self.build_feature_vector(ticker, date, keep_pred=False)\n",
    "                if type(vector) != int:\n",
    "                    vector_list.append(vector)\n",
    "                    index_list.append(ticker)\n",
    "\n",
    "        start_time = time()\n",
    "        test_df = pd.concat(vector_list)\n",
    "        print(time() - start_time)\n",
    "        return test_df.reset_index(drop=True), index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TEG: No data found for this date range, symbol may be delisted\n",
      "- ANDV: No data found for this date range, symbol may be delisted\n",
      "- BRCM: No data found for this date range, symbol may be delisted\n",
      "- RAI: No data found for this date range, symbol may be delisted\n",
      "- SNDK: No data found for this date range, symbol may be delisted\n",
      "- CSC: No data found for this date range, symbol may be delisted\n",
      "- XL: No data found for this date range, symbol may be delisted\n",
      "- KRFT: No data found for this date range, symbol may be delisted\n",
      "- HSP: No data found for this date range, symbol may be delisted\n",
      "- YHOO: No data found for this date range, symbol may be delisted\n",
      "- AET: No data found for this date range, symbol may be delisted\n",
      "- TWC: No data found for this date range, symbol may be delisted\n",
      "- WYN: No data found for this date range, symbol may be delisted\n",
      "- GGP: No data found for this date range, symbol may be delisted\n",
      "- SPLS: No data found for this date range, symbol may be delisted\n",
      "- BF.B: No data found for this date range, symbol may be delisted\n",
      "- VIAB: No data found, symbol may be delisted\n",
      "- GMCR: No data found for this date range, symbol may be delisted\n",
      "- BRK.B: No data found, symbol may be delisted\n",
      "- ESV: No data found, symbol may be delisted\n",
      "- EMC: No data found for this date range, symbol may be delisted\n",
      "- HAR: No data found for this date range, symbol may be delisted\n",
      "- GAS: No data found for this date range, symbol may be delisted\n",
      "- DO: No data found, symbol may be delisted\n",
      "- CCE: No data found for this date range, symbol may be delisted\n",
      "- BCR: No data found for this date range, symbol may be delisted\n",
      "- LO: No data found for this date range, symbol may be delisted\n",
      "- DTV: No data found, symbol may be delisted\n",
      "- CAM: No data found for this date range, symbol may be delisted\n",
      "- LVLT: No data found for this date range, symbol may be delisted\n",
      "- STJ: No data found for this date range, symbol may be delisted\n",
      "- RHT: No data found, symbol may be delisted\n",
      "- CFN: No data found for this date range, symbol may be delisted\n",
      "- FDO: No data found for this date range, symbol may be delisted\n",
      "- CVC: No data found for this date range, symbol may be delisted\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-980cc1c063de>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tickers, hist_depth, train_depth, features, data_path, prefix, interval, data_start, target)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblacklist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mportfolio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_portfolio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtickers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mportfolio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-980cc1c063de>\u001b[0m in \u001b[0;36mbuild_portfolio\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m60\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mticker_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-980cc1c063de>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, return_bad_tickers)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_hist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mbad_tickers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_bad_tickers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2019-12-01'\n",
    "universe = build_snp('January 1, 2015', '%B %d, %Y')\n",
    "\n",
    "hist_depth = 12\n",
    "train_depth = 6\n",
    "\n",
    "port = Portfolio(\n",
    "    universe, \n",
    "    hist_depth=hist_depth, \n",
    "    train_depth=train_depth, \n",
    "    features = ['Close', 'Volume']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'port' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7291619a6882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_feature_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AAPL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2015-01-01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'port' is not defined"
     ]
    }
   ],
   "source": [
    "# return feature_df\n",
    "\n",
    "\n",
    "vec = port.build_feature_vector('AAPL', '2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_vec = list(vec.iloc[:-1].values.flatten())\n",
    "# new_vec.append(vec['Close'].iloc[-1])\n",
    "\n",
    "new_vec = list(vec.values[:-1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.115517854690552\n",
      "CPU times: user 13.9 s, sys: 38.2 ms, total: 14 s\n",
      "Wall time: 14 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close 1</th>\n",
       "      <th>Volume 1</th>\n",
       "      <th>Close 2</th>\n",
       "      <th>Volume 2</th>\n",
       "      <th>Close 3</th>\n",
       "      <th>Volume 3</th>\n",
       "      <th>Close 4</th>\n",
       "      <th>Volume 4</th>\n",
       "      <th>Close 5</th>\n",
       "      <th>Volume 5</th>\n",
       "      <th>...</th>\n",
       "      <th>Volume 8</th>\n",
       "      <th>Close 9</th>\n",
       "      <th>Volume 9</th>\n",
       "      <th>Close 10</th>\n",
       "      <th>Volume 10</th>\n",
       "      <th>Close 11</th>\n",
       "      <th>Volume 11</th>\n",
       "      <th>Close 12</th>\n",
       "      <th>Volume 12</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.87</td>\n",
       "      <td>25502300.0</td>\n",
       "      <td>44.10</td>\n",
       "      <td>35798500.0</td>\n",
       "      <td>51.84</td>\n",
       "      <td>50804900.0</td>\n",
       "      <td>53.28</td>\n",
       "      <td>39031700.0</td>\n",
       "      <td>50.55</td>\n",
       "      <td>42417700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32657400.0</td>\n",
       "      <td>49.80</td>\n",
       "      <td>23803000.0</td>\n",
       "      <td>45.26</td>\n",
       "      <td>35610300.0</td>\n",
       "      <td>51.98</td>\n",
       "      <td>59152000.0</td>\n",
       "      <td>53.33</td>\n",
       "      <td>29448100.0</td>\n",
       "      <td>54.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.27</td>\n",
       "      <td>25012700.0</td>\n",
       "      <td>45.87</td>\n",
       "      <td>25502300.0</td>\n",
       "      <td>44.10</td>\n",
       "      <td>35798500.0</td>\n",
       "      <td>51.84</td>\n",
       "      <td>50804900.0</td>\n",
       "      <td>53.28</td>\n",
       "      <td>39031700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33520700.0</td>\n",
       "      <td>49.37</td>\n",
       "      <td>32657400.0</td>\n",
       "      <td>49.80</td>\n",
       "      <td>23803000.0</td>\n",
       "      <td>45.26</td>\n",
       "      <td>35610300.0</td>\n",
       "      <td>51.98</td>\n",
       "      <td>59152000.0</td>\n",
       "      <td>53.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.95</td>\n",
       "      <td>34405700.0</td>\n",
       "      <td>44.27</td>\n",
       "      <td>25012700.0</td>\n",
       "      <td>45.87</td>\n",
       "      <td>25502300.0</td>\n",
       "      <td>44.10</td>\n",
       "      <td>35798500.0</td>\n",
       "      <td>51.84</td>\n",
       "      <td>50804900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33499300.0</td>\n",
       "      <td>49.82</td>\n",
       "      <td>33520700.0</td>\n",
       "      <td>49.37</td>\n",
       "      <td>32657400.0</td>\n",
       "      <td>49.80</td>\n",
       "      <td>23803000.0</td>\n",
       "      <td>45.26</td>\n",
       "      <td>35610300.0</td>\n",
       "      <td>51.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.99</td>\n",
       "      <td>26804900.0</td>\n",
       "      <td>42.95</td>\n",
       "      <td>34405700.0</td>\n",
       "      <td>44.27</td>\n",
       "      <td>25012700.0</td>\n",
       "      <td>45.87</td>\n",
       "      <td>25502300.0</td>\n",
       "      <td>44.10</td>\n",
       "      <td>35798500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42417700.0</td>\n",
       "      <td>50.06</td>\n",
       "      <td>33499300.0</td>\n",
       "      <td>49.82</td>\n",
       "      <td>33520700.0</td>\n",
       "      <td>49.37</td>\n",
       "      <td>32657400.0</td>\n",
       "      <td>49.80</td>\n",
       "      <td>23803000.0</td>\n",
       "      <td>45.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.26</td>\n",
       "      <td>22686800.0</td>\n",
       "      <td>42.99</td>\n",
       "      <td>26804900.0</td>\n",
       "      <td>42.95</td>\n",
       "      <td>34405700.0</td>\n",
       "      <td>44.27</td>\n",
       "      <td>25012700.0</td>\n",
       "      <td>45.87</td>\n",
       "      <td>25502300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39031700.0</td>\n",
       "      <td>50.55</td>\n",
       "      <td>42417700.0</td>\n",
       "      <td>50.06</td>\n",
       "      <td>33499300.0</td>\n",
       "      <td>49.82</td>\n",
       "      <td>33520700.0</td>\n",
       "      <td>49.37</td>\n",
       "      <td>32657400.0</td>\n",
       "      <td>49.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>42.07</td>\n",
       "      <td>32228500.0</td>\n",
       "      <td>43.98</td>\n",
       "      <td>31869800.0</td>\n",
       "      <td>40.11</td>\n",
       "      <td>44831100.0</td>\n",
       "      <td>41.68</td>\n",
       "      <td>39759000.0</td>\n",
       "      <td>41.93</td>\n",
       "      <td>43647600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35423300.0</td>\n",
       "      <td>42.28</td>\n",
       "      <td>36674700.0</td>\n",
       "      <td>45.73</td>\n",
       "      <td>27846000.0</td>\n",
       "      <td>45.70</td>\n",
       "      <td>44781000.0</td>\n",
       "      <td>45.82</td>\n",
       "      <td>62790200.0</td>\n",
       "      <td>45.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>42.65</td>\n",
       "      <td>37883600.0</td>\n",
       "      <td>42.07</td>\n",
       "      <td>32228500.0</td>\n",
       "      <td>43.98</td>\n",
       "      <td>31869800.0</td>\n",
       "      <td>40.11</td>\n",
       "      <td>44831100.0</td>\n",
       "      <td>41.68</td>\n",
       "      <td>39759000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26638900.0</td>\n",
       "      <td>41.16</td>\n",
       "      <td>35423300.0</td>\n",
       "      <td>42.28</td>\n",
       "      <td>36674700.0</td>\n",
       "      <td>45.73</td>\n",
       "      <td>27846000.0</td>\n",
       "      <td>45.70</td>\n",
       "      <td>44781000.0</td>\n",
       "      <td>45.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>40.09</td>\n",
       "      <td>41976300.0</td>\n",
       "      <td>42.65</td>\n",
       "      <td>37883600.0</td>\n",
       "      <td>42.07</td>\n",
       "      <td>32228500.0</td>\n",
       "      <td>43.98</td>\n",
       "      <td>31869800.0</td>\n",
       "      <td>40.11</td>\n",
       "      <td>44831100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40244800.0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>26638900.0</td>\n",
       "      <td>41.16</td>\n",
       "      <td>35423300.0</td>\n",
       "      <td>42.28</td>\n",
       "      <td>36674700.0</td>\n",
       "      <td>45.73</td>\n",
       "      <td>27846000.0</td>\n",
       "      <td>45.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>37.20</td>\n",
       "      <td>39249200.0</td>\n",
       "      <td>40.09</td>\n",
       "      <td>41976300.0</td>\n",
       "      <td>42.65</td>\n",
       "      <td>37883600.0</td>\n",
       "      <td>42.07</td>\n",
       "      <td>32228500.0</td>\n",
       "      <td>43.98</td>\n",
       "      <td>31869800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43647600.0</td>\n",
       "      <td>43.25</td>\n",
       "      <td>40244800.0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>26638900.0</td>\n",
       "      <td>41.16</td>\n",
       "      <td>35423300.0</td>\n",
       "      <td>42.28</td>\n",
       "      <td>36674700.0</td>\n",
       "      <td>45.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>38.26</td>\n",
       "      <td>38363600.0</td>\n",
       "      <td>37.20</td>\n",
       "      <td>39249200.0</td>\n",
       "      <td>40.09</td>\n",
       "      <td>41976300.0</td>\n",
       "      <td>42.65</td>\n",
       "      <td>37883600.0</td>\n",
       "      <td>42.07</td>\n",
       "      <td>32228500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39759000.0</td>\n",
       "      <td>41.93</td>\n",
       "      <td>43647600.0</td>\n",
       "      <td>43.25</td>\n",
       "      <td>40244800.0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>26638900.0</td>\n",
       "      <td>41.16</td>\n",
       "      <td>35423300.0</td>\n",
       "      <td>42.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2562 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Close 1    Volume 1  Close 2    Volume 2  Close 3    Volume 3  Close 4  \\\n",
       "0       45.87  25502300.0    44.10  35798500.0    51.84  50804900.0    53.28   \n",
       "1       44.27  25012700.0    45.87  25502300.0    44.10  35798500.0    51.84   \n",
       "2       42.95  34405700.0    44.27  25012700.0    45.87  25502300.0    44.10   \n",
       "3       42.99  26804900.0    42.95  34405700.0    44.27  25012700.0    45.87   \n",
       "4       41.26  22686800.0    42.99  26804900.0    42.95  34405700.0    44.27   \n",
       "...       ...         ...      ...         ...      ...         ...      ...   \n",
       "2557    42.07  32228500.0    43.98  31869800.0    40.11  44831100.0    41.68   \n",
       "2558    42.65  37883600.0    42.07  32228500.0    43.98  31869800.0    40.11   \n",
       "2559    40.09  41976300.0    42.65  37883600.0    42.07  32228500.0    43.98   \n",
       "2560    37.20  39249200.0    40.09  41976300.0    42.65  37883600.0    42.07   \n",
       "2561    38.26  38363600.0    37.20  39249200.0    40.09  41976300.0    42.65   \n",
       "\n",
       "        Volume 4  Close 5    Volume 5  ...    Volume 8  Close 9    Volume 9  \\\n",
       "0     39031700.0    50.55  42417700.0  ...  32657400.0    49.80  23803000.0   \n",
       "1     50804900.0    53.28  39031700.0  ...  33520700.0    49.37  32657400.0   \n",
       "2     35798500.0    51.84  50804900.0  ...  33499300.0    49.82  33520700.0   \n",
       "3     25502300.0    44.10  35798500.0  ...  42417700.0    50.06  33499300.0   \n",
       "4     25012700.0    45.87  25502300.0  ...  39031700.0    50.55  42417700.0   \n",
       "...          ...      ...         ...  ...         ...      ...         ...   \n",
       "2557  39759000.0    41.93  43647600.0  ...  35423300.0    42.28  36674700.0   \n",
       "2558  44831100.0    41.68  39759000.0  ...  26638900.0    41.16  35423300.0   \n",
       "2559  31869800.0    40.11  44831100.0  ...  40244800.0    42.31  26638900.0   \n",
       "2560  32228500.0    43.98  31869800.0  ...  43647600.0    43.25  40244800.0   \n",
       "2561  37883600.0    42.07  32228500.0  ...  39759000.0    41.93  43647600.0   \n",
       "\n",
       "      Close 10   Volume 10  Close 11   Volume 11  Close 12   Volume 12  Target  \n",
       "0        45.26  35610300.0     51.98  59152000.0     53.33  29448100.0   54.30  \n",
       "1        49.80  23803000.0     45.26  35610300.0     51.98  59152000.0   53.33  \n",
       "2        49.37  32657400.0     49.80  23803000.0     45.26  35610300.0   51.98  \n",
       "3        49.82  33520700.0     49.37  32657400.0     49.80  23803000.0   45.26  \n",
       "4        50.06  33499300.0     49.82  33520700.0     49.37  32657400.0   49.80  \n",
       "...        ...         ...       ...         ...       ...         ...     ...  \n",
       "2557     45.73  27846000.0     45.70  44781000.0     45.82  62790200.0   45.45  \n",
       "2558     42.28  36674700.0     45.73  27846000.0     45.70  44781000.0   45.82  \n",
       "2559     41.16  35423300.0     42.28  36674700.0     45.73  27846000.0   45.70  \n",
       "2560     42.31  26638900.0     41.16  35423300.0     42.28  36674700.0   45.73  \n",
       "2561     43.25  40244800.0     42.31  26638900.0     41.16  35423300.0   42.28  \n",
       "\n",
       "[2562 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "port.build_train_df('2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# port.build_test_df('2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8722813232690143"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(30))[0:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1.1**5 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x/100)**(1/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([1, 2, 3, 4, 5]).add(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1 * 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
