{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 µs, sys: 1 µs, total: 25 µs\n",
      "Wall time: 26.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from time import sleep, time\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to maintain and call the S&P 500 from a current date\n",
    "# Author Michael Djaballah\n",
    "# Time last edited: 5:56 PM June 1, 2020\n",
    "# Last edited by: Michael Djaballah\n",
    "\n",
    "# Takes no input\n",
    "# Output is newly saved CSV's containing the current makeup of the S&P 500 \n",
    "# and its historical additions and removals\n",
    "# data_path is changeable depending on desired save location\n",
    "def get_snp_store(data_path='data/'):\n",
    "    curr_raw = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    \n",
    "    curr = curr_raw[0]\n",
    "    hist = curr_raw[1]\n",
    "    \n",
    "    new_hist = pd.DataFrame(hist['Date'])\n",
    "    new_hist['Added'] = hist['Added', 'Ticker']\n",
    "    new_hist['Removed'] = hist['Removed', 'Ticker']\n",
    "    \n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    \n",
    "    curr.to_csv(data_path + 'snp_current.csv', index=False)\n",
    "    new_hist.to_csv(data_path + 'snp_hist.csv', index=False)\n",
    "    return None\n",
    "\n",
    "\n",
    "# Input: a date in string form with its corresponding format:\n",
    "# Ex: 'January 1, 2020', '%B %d, %Y'\n",
    "# Output: a list containing the S&P 500 at the input date\n",
    "def build_snp(date, date_format, data_path='data/'):\n",
    "    curr = pd.read_csv(data_path + 'snp_current.csv')\n",
    "    hist = pd.read_csv(data_path + 'snp_hist.csv')\n",
    "    \n",
    "    start_date = datetime.strptime(date, date_format)\n",
    "    \n",
    "    snp_set = set(curr['Symbol'])\n",
    "    \n",
    "    for i in range(len(hist)):\n",
    "        temp_date = datetime.strptime(hist.iloc[i]['Date'], date_format)\n",
    "        if temp_date < start_date:\n",
    "            break\n",
    "\n",
    "        tb_removed = hist.iloc[i]['Added']\n",
    "        tb_added = hist.iloc[i]['Removed']\n",
    "\n",
    "        if tb_removed in snp_set:\n",
    "            snp_set.remove(tb_removed)\n",
    "        if not type(tb_added) == float:\n",
    "            snp_set.add(tb_added)\n",
    "    \n",
    "    return list(snp_set)\n",
    "\n",
    "# Included to build returns for a SPY comparison\n",
    "# Input is a portfolio (ticker:df dictionary), the tickers desired for returns, and the date of returns\n",
    "# Output is a list of floats that are returns\n",
    "def build_returns(portfolio, tickers, date):\n",
    "    returns = []\n",
    "    for ticker in tickers:\n",
    "        temp_ticker_dict = portfolio[ticker].set_index('Date').loc[date]\n",
    "        returns.append((temp_ticker_dict['Close'] - temp_ticker_dict['Open'])/temp_ticker_dict['Open'])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Portfolio:\n",
    "    def __init__(self, tickers, hist_depth=None, train_depth=None, features=[], \n",
    "                 data_path = 'data/', prefix = 'monthly/', interval = '1mo', \n",
    "                 data_start = '2001-01-01', target='Close'):\n",
    "        self.portfolio = {}\n",
    "        self.tickers = tickers\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        \n",
    "        self.hist_depth = hist_depth\n",
    "        self.train_depth = train_depth\n",
    "        \n",
    "        self.interval = interval\n",
    "        self.data_start = data_start\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.prefix = prefix\n",
    "        \n",
    "        self.results = []\n",
    "        \n",
    "        self.blacklist = set()\n",
    "        \n",
    "        self.portfolio = self.build_portfolio()\n",
    "        self.tickers = list(self.portfolio.keys())\n",
    "        self.columns = self.build_columns()\n",
    "        \n",
    "    \n",
    "    def get_data(self, return_bad_tickers=False):\n",
    "        bad_tickers = []\n",
    "\n",
    "        os.makedirs(self.data_path + self.prefix, exist_ok=True)\n",
    "\n",
    "        curr_tickers = set(os.listdir(self.data_path + self.prefix))\n",
    "\n",
    "        for ticker in self.tickers:\n",
    "            ticker_label = ticker + '.csv'\n",
    "\n",
    "            if ticker_label not in curr_tickers:\n",
    "                temp_ticker = yf.Ticker(ticker)\n",
    "                temp_hist = temp_ticker.history(start=self.data_start, interval=self.interval)\n",
    "                temp_hist.dropna(axis=0, inplace=True)\n",
    "                temp_hist.to_csv(self.data_path + self.prefix + ticker_label)\n",
    "\n",
    "                if len(temp_hist) < 90:\n",
    "                    bad_tickers.append((ticker, len(temp_hist)))\n",
    "                sleep(.5)\n",
    "\n",
    "        if return_bad_tickers:\n",
    "            return bad_tickers\n",
    "\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def build_columns(self):\n",
    "        columns = []\n",
    "        for i in range(self.hist_depth):\n",
    "            for feature in self.features:\n",
    "                columns.append(feature + ' ' + str(i + 1))\n",
    "        return columns\n",
    "    \n",
    "    \n",
    "    def check_ticker(self, ticker, offset):\n",
    "        ticker_df = pd.read_csv(self.data_path + self.prefix + ticker + '.csv')\n",
    "        if len(ticker_df) >= offset:\n",
    "            return ticker_df\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    def build_portfolio(self):\n",
    "        offset = self.train_depth + self.hist_depth + 60 + 12\n",
    "\n",
    "        self.get_data()\n",
    "\n",
    "        ticker_dict = {}\n",
    "\n",
    "        for ticker in self.tickers:\n",
    "            if ticker not in self.blacklist:\n",
    "                ticker_df = self.check_ticker(ticker, offset)\n",
    "                if type(ticker_df) != bool:\n",
    "                    ticker_df.set_index('Date', inplace=True)\n",
    "                    ticker_df.index = pd.to_datetime(ticker_df.index)\n",
    "                    ticker_dict[ticker] = ticker_df\n",
    "\n",
    "        return ticker_dict\n",
    "    \n",
    "    \n",
    "    def build_returns(self, symbols, date):\n",
    "        returns = []\n",
    "        for ticker in symbols:\n",
    "            temp_ticker_dict = self.portfolio[ticker].set_index('Date').loc[date]\n",
    "            returns.append((temp_ticker_dict['Close'] - temp_ticker_dict['Open'])/temp_ticker_dict['Open'])\n",
    "        return returns\n",
    "    \n",
    "    \n",
    "    def build_scaled_df(self, dataframe):\n",
    "        scaler = StandardScaler()\n",
    "        scaled_array = scaler.fit_transform(dataframe)\n",
    "        scaled_dataframe = pd.DataFrame(scaled_array, columns=dataframe.columns)\n",
    "        return scaled_dataframe\n",
    "    \n",
    "    \n",
    "    def check_date(self, ticker, date):\n",
    "        dates = set(self.portfolio[ticker]['Date'])\n",
    "        return date in dates\n",
    "    \n",
    "    \n",
    "    def build_machine(self, model, date, n=15):\n",
    "        train_df = self.build_train_df(date)\n",
    "        scaled_train_df = self.build_scaled_df(train_df)\n",
    "\n",
    "        scaled_train_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "        X = scaled_train_df.values[:,:-1]\n",
    "        y = scaled_train_df.values[:, -1]\n",
    "        model.fit(X, y)\n",
    "\n",
    "        test_df, symbols = self.build_test_df(date)\n",
    "        scaled_test_df = self.build_scaled_df(test_df)\n",
    "        X_test = scaled_test_df.values\n",
    "\n",
    "        predicted_returns = list(model.predict(X))\n",
    "\n",
    "        returns_dict = {}\n",
    "\n",
    "        for i in range(len(symbols)):\n",
    "            returns_dict[symbols[i]] = predicted_returns[i]\n",
    "\n",
    "        top = sorted(returns_dict.items(), key=lambda x: x[1])[::-1][:n]\n",
    "        return [x[0] for x in top]\n",
    "    \n",
    "    \n",
    "    def backtest(self, model, start_date, end_date):\n",
    "        months = list(pd.date_range(start_date, end_date, freq='MS').strftime('%Y-%m-%d'))\n",
    "\n",
    "        overall_returns = []\n",
    "        specific_returns = []\n",
    "        for month in months:\n",
    "            start_time = time()\n",
    "            for ticker in self.tickers:\n",
    "                if ticker not in self.blacklist:\n",
    "                    if not self.check_date(ticker, month):\n",
    "                        self.blacklist.add(ticker)\n",
    "            symbols = self.build_machine(model, month)\n",
    "            ticker_returns = self.build_returns(symbols, month)\n",
    "            overall_returns.append(sum(ticker_returns)/len(ticker_returns))\n",
    "            print(month, round(sum(ticker_returns)/len(ticker_returns), 6), round(time()-start_time, 2))\n",
    "            \n",
    "            specific_returns_dict = {}\n",
    "            for i in range(len(ticker_returns)):\n",
    "                specific_returns_dict[symbols[i]] = ticker_returns[i]\n",
    "            specific_returns.append(specific_returns_dict)\n",
    "            \n",
    "        self.results = specific_returns\n",
    "        return overall_returns\n",
    "    \n",
    "    \n",
    "#     def build_feature_vector(self, ticker, date, keep_pred=True):\n",
    "#         ticker_df = self.portfolio[ticker]\n",
    "\n",
    "#         start_date_dt = datetime.strptime(date, '%Y-%m-%d') - relativedelta(months=self.hist_depth)\n",
    "#         start_date = start_date_dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#         feature_df = ticker_df.set_index('Date')[start_date:date].reset_index(drop=True)[self.features]\n",
    "        \n",
    "#         new_df_dict = {}\n",
    "\n",
    "#         for i in range(len(feature_df)):\n",
    "#             for col in feature_df.columns:\n",
    "#                 if i < len(feature_df) - 1:\n",
    "#                     new_df_dict[col + ' ' + str(i + 1)] = [feature_df[col].iloc[i]]\n",
    "#                 elif col == self.target:\n",
    "#                     if keep_pred:\n",
    "#                         new_df_dict['Target'] = [feature_df[col].iloc[i]]\n",
    "\n",
    "#         new_df = pd.DataFrame.from_dict(new_df_dict)\n",
    "        \n",
    "#         if len(new_df) == 0:\n",
    "#             self.blacklist.add(ticker)\n",
    "#             return -1\n",
    "\n",
    "#         if keep_pred:\n",
    "#             new_df = new_df[[col for col in list(new_df.columns) if col not in {'Target'}] + ['Target']]\n",
    "        \n",
    "#         return new_df\n",
    "    \n",
    "    \n",
    "#     def build_train_df(self, date):    \n",
    "#         vector_list = []\n",
    "#         for ticker in self.tickers:\n",
    "#             if ticker not in self.blacklist:\n",
    "#                 for i in range(self.train_depth):\n",
    "#                     train_start_dt = datetime.strptime(date, '%Y-%m-%d') - relativedelta(months=(1+i))\n",
    "#                     train_start = train_start_dt.strftime('%Y-%m-%d')\n",
    "#                     vector = self.build_feature_vector(ticker, train_start)\n",
    "                    \n",
    "#                     if type(vector) != int:\n",
    "#                         vector_list.append(vector)\n",
    "        \n",
    "#         start_time = time()\n",
    "#         feature_df = pd.concat(vector_list)\n",
    "#         print(time() - start_time)\n",
    "#         return feature_df.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "#     def build_test_df(self, date):\n",
    "#         vector_list = []\n",
    "#         index_list = []\n",
    "#         for ticker in self.tickers:\n",
    "#             if ticker not in self.blacklist:\n",
    "#                 vector = self.build_feature_vector(ticker, date, keep_pred=False)\n",
    "#                 if type(vector) != int:\n",
    "#                     vector_list.append(vector)\n",
    "#                     index_list.append(ticker)\n",
    "\n",
    "#         start_time = time()\n",
    "#         test_df = pd.concat(vector_list)\n",
    "#         print(time() - start_time)\n",
    "#         return test_df.reset_index(drop=True), index_list\n",
    "    \n",
    "    \n",
    "    def build_feature_vector(self, ticker, date, keep_pred=True):\n",
    "        ticker_df = self.portfolio[ticker]\n",
    "\n",
    "        start_date_dt = datetime.strptime(date, '%Y-%m-%d') - relativedelta(months=self.hist_depth)\n",
    "        start_date = start_date_dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        feature_df = ticker_df.loc[start_date:date][self.features]\n",
    "        \n",
    "        new_df_dict = {}\n",
    "\n",
    "        for i in range(len(feature_df)):\n",
    "            for col in feature_df.columns:\n",
    "                if i < len(feature_df) - 1:\n",
    "                    new_df_dict[col + ' ' + str(i + 1)] = [feature_df[col].iloc[i]]\n",
    "                elif col == self.target:\n",
    "                    if keep_pred:\n",
    "                        new_df_dict['Target'] = [feature_df[col].iloc[i]]\n",
    "\n",
    "        new_df = pd.DataFrame.from_dict(new_df_dict)\n",
    "        \n",
    "        if len(new_df) == 0:\n",
    "            self.blacklist.add(ticker)\n",
    "            return -1\n",
    "\n",
    "        if keep_pred:\n",
    "            new_df = new_df[[col for col in list(new_df.columns) if col not in {'Target'}] + ['Target']]\n",
    "        \n",
    "        return new_df\n",
    "    \n",
    "    \n",
    "    def build_train_df(self, date):    \n",
    "        vector_list = []\n",
    "        for ticker in self.tickers:\n",
    "            if ticker not in self.blacklist:\n",
    "                for i in range(self.train_depth):\n",
    "                    train_start_dt = datetime.strptime(date, '%Y-%m-%d') - relativedelta(months=(1+i))\n",
    "                    train_start = train_start_dt.strftime('%Y-%m-%d')\n",
    "                    vector = self.build_feature_vector(ticker, train_start)\n",
    "                    \n",
    "                    if type(vector) != int:\n",
    "                        vector_list.append(vector)\n",
    "        \n",
    "#         start_time = time()\n",
    "        feature_df = pd.concat(vector_list)\n",
    "#         print(time() - start_time)\n",
    "        return feature_df.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    def build_test_df(self, date):\n",
    "        vector_list = []\n",
    "        index_list = []\n",
    "        for ticker in self.tickers:\n",
    "            if ticker not in self.blacklist:\n",
    "                vector = self.build_feature_vector(ticker, date, keep_pred=False)\n",
    "                if type(vector) != int:\n",
    "                    vector_list.append(vector)\n",
    "                    index_list.append(ticker)\n",
    "\n",
    "#         start_time = time()\n",
    "        test_df = pd.concat(vector_list)\n",
    "#         print(time() - start_time)\n",
    "        return test_df.reset_index(drop=True), index_list\n",
    "    \n",
    "    \n",
    "    def build_train(self, date):\n",
    "        X = np.zeros((self.train_depth * len(self.portfolio), self.hist_depth * len(self.features)))\n",
    "        y = np.zeros(self.train_depth * len(self.portfolio))\n",
    "        j = 0\n",
    "        for ticker in self.portfolio:\n",
    "            ticker_df = self.portfolio[ticker]\n",
    "            date_i = ticker_df.index.get_loc(date)\n",
    "            for i in range(1, self.train_depth + 1):\n",
    "                start = date_i - i - self.hist_depth\n",
    "                end = date_i - i \n",
    "                X[j] = ticker_df.iloc[start:end][self.features].values.flatten()\n",
    "                y[j] = ticker_df.iloc[date_i - i + 1][self.target]\n",
    "                j += 1\n",
    "        return X, y\n",
    "    \n",
    "    \n",
    "    def build_test(self, date):\n",
    "        X = np.zeros((len(self.portfolio), self.hist_depth * len(self.features)))\n",
    "        tickers = list(self.portfolio.keys())\n",
    "        j = 0\n",
    "        for ticker in tickers:\n",
    "            ticker_df = self.portfolio[ticker]\n",
    "            date_i = ticker_df.index.get_loc(date)\n",
    "            start = date_i - self.hist_depth\n",
    "            end = date_i\n",
    "            X[j] = ticker_df.iloc[start:end][self.features].values.flatten()\n",
    "            j += 1\n",
    "        return X, tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 748 ms, sys: 0 ns, total: 748 ms\n",
      "Wall time: 747 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2019-12-01'\n",
    "universe = build_snp('January 1, 2015', '%B %d, %Y')\n",
    "\n",
    "hist_depth = 6\n",
    "train_depth = 6\n",
    "features = ['Close', 'Volume']\n",
    "target = 'Close'\n",
    "\n",
    "port = Portfolio(\n",
    "    universe, \n",
    "    hist_depth=hist_depth, \n",
    "    train_depth=train_depth, \n",
    "    features = features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.43 s, sys: 0 ns, total: 1.43 s\n",
      "Wall time: 1.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nan = port.build_train(start_date)\n",
    "# nan = port.build_test(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.23 s, sys: 0 ns, total: 6.23 s\n",
      "Wall time: 6.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nan = port.build_train_df(start_date)\n",
    "# nan = port.build_test_df(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.14 s, sys: 13 µs, total: 1.14 s\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "date = '2015-01-01'\n",
    "X = np.zeros((train_depth * len(port.portfolio), hist_depth * len(features)))\n",
    "y = np.zeros(train_depth * len(port.portfolio))\n",
    "j = 0\n",
    "for ticker in port.portfolio:\n",
    "    ticker_df = port.portfolio[ticker]\n",
    "    date_i = ticker_df.index.get_loc(date)\n",
    "    for i in range(1, train_depth + 1):\n",
    "        start = date_i - i - hist_depth\n",
    "        end = date_i - i \n",
    "        X[j] = ticker_df.iloc[start:end][features].values.flatten()\n",
    "        y[j] = ticker_df.iloc[date_i - i + 1][target]\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = np.zeros((len(port.portfolio), hist_depth * len(features)))\n",
    "j = 0\n",
    "for ticker in port.portfolio:\n",
    "    ticker_df = port.portfolio[ticker]\n",
    "    date_i = ticker_df.index.get_loc(date)\n",
    "    start = date_i - hist_depth\n",
    "    end = date_i\n",
    "    X_t[j] = ticker_df.iloc[start:end][features].values.flatten()\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[7.51600e+01, 3.34308e+07, 8.12900e+01, ..., 7.22552e+07,\n",
       "         8.26100e+01, 3.25797e+07],\n",
       "        [7.45300e+01, 3.54105e+07, 7.51600e+01, ..., 3.37439e+07,\n",
       "         8.05800e+01, 7.22552e+07],\n",
       "        [6.92200e+01, 5.03555e+07, 7.45300e+01, ..., 4.35210e+07,\n",
       "         8.30900e+01, 3.37439e+07],\n",
       "        ...,\n",
       "        [5.02500e+01, 2.98535e+07, 5.02400e+01, ..., 2.73774e+07,\n",
       "         5.28800e+01, 3.28400e+07],\n",
       "        [4.87100e+01, 4.75973e+07, 5.02500e+01, ..., 3.96465e+07,\n",
       "         5.13500e+01, 2.73774e+07],\n",
       "        [4.91100e+01, 4.72723e+07, 4.87100e+01, ..., 2.98092e+07,\n",
       "         4.90700e+01, 3.96465e+07]]),\n",
       " array([81.66, 81.11, 82.61, ..., 60.46, 54.44, 52.88]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port.build_train('2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[8.129000e+01, 4.352100e+07, 8.309000e+01, ..., 3.257970e+07,\n",
       "         8.111000e+01, 4.051990e+07],\n",
       "        [6.425000e+01, 3.829480e+07, 6.490000e+01, ..., 4.029390e+07,\n",
       "         7.264000e+01, 4.017710e+07],\n",
       "        [4.051000e+01, 3.179900e+07, 4.100000e+01, ..., 3.434450e+07,\n",
       "         4.462000e+01, 5.362590e+07],\n",
       "        ...,\n",
       "        [1.459400e+02, 2.372420e+07, 1.556600e+02, ..., 2.539530e+07,\n",
       "         1.653100e+02, 2.629690e+07],\n",
       "        [2.101000e+01, 5.669110e+08, 2.071000e+01, ..., 5.372423e+08,\n",
       "         2.061000e+01, 9.016472e+08],\n",
       "        [5.135000e+01, 2.737740e+07, 5.288000e+01, ..., 3.060180e+07,\n",
       "         6.024000e+01, 3.093200e+07]]),\n",
       " dict_keys(['EXPE', 'MAR', 'WM', 'FIS', 'PRU', 'ETFC', 'NDAQ', 'XEL', 'AIG', 'AEE', 'ROP', 'WELL', 'LH', 'DD', 'EXC', 'SJM', 'PCAR', 'WFC', 'MYL', 'AME', 'CRM', 'AMAT', 'TROW', 'MLM', 'VRSN', 'AXP', 'BAC', 'SBUX', 'FOSL', 'TDC', 'APH', 'DGX', 'NBL', 'MCD', 'TGT', 'GT', 'GM', 'PDCO', 'CL', 'JCI', 'MDLZ', 'ALLE', 'KMI', 'TPR', 'RIG', 'FE', 'LHX', 'VAR', 'USB', 'ATI', 'IBM', 'PCG', 'AMGN', 'QCOM', 'MMM', 'OKE', 'HSY', 'MA', 'AZO', 'ZTS', 'INTC', 'HP', 'FLR', 'NBR', 'A', 'TJX', 'ADS', 'KMB', 'CB', 'PWR', 'SRE', 'RCL', 'ECL', 'ISRG', 'JEF', 'NOC', 'NOV', 'DTE', 'GILD', 'HON', 'ALXN', 'UAA', 'T', 'AON', 'EQR', 'ESS', 'QEP', 'C', 'PEG', 'KSS', 'JNPR', 'DISCA', 'PEP', 'AMT', 'WMT', 'OI', 'HAS', 'MCO', 'APA', 'TRV', 'RRC', 'ETR', 'DLTR', 'GS', 'LUV', 'ADM', 'LRCX', 'MCK', 'FDX', 'AIV', 'NE', 'PAYX', 'PFE', 'VMC', 'MO', 'RF', 'PBCT', 'PPG', 'DNR', 'REGN', 'IVZ', 'AMG', 'MS', 'AMP', 'BBBY', 'ADBE', 'CMS', 'BA', 'AAPL', 'MSI', 'MMC', 'VZ', 'SWN', 'ORCL', 'DAL', 'AES', 'SYY', 'ZION', 'MUR', 'MU', 'DISCK', 'LEN', 'FLS', 'TMO', 'TSN', 'UNH', 'CAT', 'TXT', 'V', 'MRK', 'LIN', 'EOG', 'MHK', 'SO', 'AKAM', 'PRGO', 'KR', 'IQV', 'AVGO', 'EMR', 'UNP', 'K', 'CMA', 'FB', 'CCI', 'OMC', 'GOOG', 'GPC', 'APTV', 'NTRS', 'TIF', 'GLW', 'AFL', 'NWSA', 'NEM', 'DIS', 'WAT', 'THC', 'MNST', 'HRB', 'ANTM', 'PEAK', 'VTR', 'ITW', 'UPS', 'AN', 'KO', 'HPQ', 'CSCO', 'GNW', 'HRL', 'NVDA', 'KIM', 'PSX', 'CPB', 'HST', 'URI', 'DG', 'L', 'SNA', 'ABBV', 'BLK', 'ADI', 'DE', 'OXY', 'CI', 'SHW', 'MOS', 'NSC', 'NRG', 'MPC', 'NUE', 'TAP', 'CAG', 'SYK', 'IRM', 'HD', 'MAC', 'WHR', 'EL', 'SPG', 'AIZ', 'NKE', 'COF', 'HBAN', 'STZ', 'APD', 'FLIR', 'TGNA', 'PBI', 'EFX', 'ORLY', 'FITB', 'CHK', 'FSLR', 'BKNG', 'BWA', 'CHRW', 'NFLX', 'TFC', 'BBY', 'CMG', 'CINF', 'IPG', 'BKR', 'SCG', 'WEC', 'MCHP', 'RSG', 'PNR', 'WBA', 'CBRE', 'SRCL', 'ADSK', 'JWN', 'EIX', 'VRTX', 'ABC', 'KSU', 'FTI', 'CPRI', 'TT', 'BK', 'GL', 'PSA', 'ABT', 'GOOGL', 'PH', 'EW', 'GWW', 'PGR', 'PM', 'LEG', 'NWL', 'POM', 'D', 'CVX', 'MNK', 'LM', 'AEP', 'ROK', 'AMZN', 'MET', 'BXP', 'DFS', 'ROST', 'CAH', 'PXD', 'DHR', 'BEN', 'CERN', 'IP', 'ALL', 'CMI', 'CVS', 'TXN', 'STX', 'BIIB', 'HUM', 'CSX', 'RHI', 'LOW', 'PFG', 'HAL', 'GIS', 'R', 'SWK', 'STT', 'PHM', 'CTAS', 'NI', 'WY', 'YUM', 'BLL', 'F', 'GD', 'WMB', 'JNJ', 'LYB', 'MTB', 'ACN', 'SLB', 'DHI', 'HOG', 'KEY', 'LB', 'M', 'HIG', 'INTU', 'XOM', 'NEE', 'JPM', 'PKI', 'ETN', 'MAS', 'XRAY', 'GPS', 'EA', 'SEE', 'IFF', 'ICE', 'MKC', 'BAX', 'AVB', 'AMCR', 'ZBH', 'DUK', 'STI', 'COP', 'SCHW', 'UHS', 'XLNX', 'SPGI', 'EBAY', 'CTL', 'COST', 'CTSH', 'PVH', 'CCL', 'BDX', 'RTX', 'AVY', 'NLSN', 'CTXS', 'WYNN', 'MRO', 'KLAC', 'XYL', 'VLO', 'NTAP', 'ADP', 'BSX', 'DVA', 'FCX', 'UNM', 'PNC', 'PG', 'VNO', 'ED', 'HES', 'FFIV', 'EXPD', 'CME', 'XRX', 'TWX', 'GME', 'GRMN', 'ES', 'WU', 'PLD', 'CLX', 'URBN', 'PNW', 'TSCO', 'COG', 'FAST', 'TEL', 'DRI', 'CNP', 'PPL', 'LLY', 'LNC', 'CF', 'RL', 'MDT', 'FMC', 'J', 'DVN', 'TRIP', 'KMX', 'XEC', 'DOV', 'EQT', 'EMN', 'MSFT', 'BMY', 'CNX', 'FISV', 'MAT', 'WDC', 'CMCSA', 'LMT', 'GE', 'VFC']))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port.build_test('2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open                  72.93\n",
       "High                  74.11\n",
       "Low                   68.80\n",
       "Close                 69.35\n",
       "Volume          41033200.00\n",
       "Dividends              0.00\n",
       "Stock Splits           0.00\n",
       "Name: 2015-01-01 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port.portfolio['MAR'].loc['2015-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0897955894470215\n",
      "CPU times: user 4.81 s, sys: 3.84 ms, total: 4.82 s\n",
      "Wall time: 4.82 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2120"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "oy = port.build_train_df('2015-01-01').values[:, -1]\n",
    "len(oy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81.11, 82.61, 80.58, ..., 54.44, 52.88, 51.35])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.49 ms, sys: 12 µs, total: 4.51 ms\n",
      "Wall time: 4.29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec = port.build_feature_vector('AAPL', '2015-06-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6730000e+01, 5.2210536e+09, 2.9310000e+01, 4.5461408e+09,\n",
       "        2.8500000e+01, 4.5545684e+09, 2.8660000e+01, 3.9845420e+09,\n",
       "        2.9840000e+01, 3.8166084e+09, 2.8850000e+01]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6730000e+01, 5.2210536e+09, 2.9310000e+01, 4.5461408e+09,\n",
       "       2.8500000e+01, 4.5545684e+09, 2.8660000e+01, 3.9845420e+09,\n",
       "       2.9840000e+01, 3.8166084e+09])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl[features].loc['2015-01-01':'2015-05-01'].values.flatten()\n",
    "# aapl[features].loc['2015-01-01':'2015-05-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>23.81</td>\n",
       "      <td>24.56</td>\n",
       "      <td>21.44</td>\n",
       "      <td>22.58</td>\n",
       "      <td>5.087392e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-01</th>\n",
       "      <td>22.38</td>\n",
       "      <td>22.94</td>\n",
       "      <td>21.48</td>\n",
       "      <td>22.43</td>\n",
       "      <td>3.243450e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-01</th>\n",
       "      <td>22.78</td>\n",
       "      <td>25.76</td>\n",
       "      <td>22.73</td>\n",
       "      <td>25.42</td>\n",
       "      <td>2.984198e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>25.38</td>\n",
       "      <td>26.22</td>\n",
       "      <td>21.58</td>\n",
       "      <td>21.87</td>\n",
       "      <td>3.489535e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close        Volume  Dividends  Stock Splits\n",
       "Date                                                                         \n",
       "2016-01-01  23.81  24.56  21.44  22.58  5.087392e+09        0.0           0.0\n",
       "2016-02-01  22.38  22.94  21.48  22.43  3.243450e+09        0.0           0.0\n",
       "2016-03-01  22.78  25.76  22.73  25.42  2.984198e+09        0.0           0.0\n",
       "2016-04-01  25.38  26.22  21.58  21.87  3.489535e+09        0.0           0.0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl = port.portfolio['AAPL']\n",
    "aapl.loc['2016-01-01':'2016-04-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(port.portfolio) * train_depth\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.44 s, sys: 36.3 ms, total: 1.48 s\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(n):\n",
    "    new_vec = aapl[features].loc['2015-01-01':'2015-05-01'].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.61 s, sys: 3.74 ms, total: 3.61 s\n",
      "Wall time: 3.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(n):\n",
    "    port.build_feature_vector('AAPL', '2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1652109622955322\n",
      "CPU times: user 4.81 s, sys: 23.3 ms, total: 4.84 s\n",
      "Wall time: 4.84 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.51600e+01, 3.34308e+07, 8.12900e+01, ..., 7.22552e+07,\n",
       "        8.26100e+01, 3.25797e+07],\n",
       "       [7.45300e+01, 3.54105e+07, 7.51600e+01, ..., 3.37439e+07,\n",
       "        8.05800e+01, 7.22552e+07],\n",
       "       [6.92200e+01, 5.03555e+07, 7.45300e+01, ..., 4.35210e+07,\n",
       "        8.30900e+01, 3.37439e+07],\n",
       "       ...,\n",
       "       [5.02500e+01, 2.98535e+07, 5.02400e+01, ..., 2.73774e+07,\n",
       "        5.28800e+01, 3.28400e+07],\n",
       "       [4.87100e+01, 4.75973e+07, 5.02500e+01, ..., 3.96465e+07,\n",
       "        5.13500e+01, 2.73774e+07],\n",
       "       [4.91100e+01, 4.72723e+07, 4.87100e+01, ..., 2.98092e+07,\n",
       "        4.90700e+01, 3.96465e+07]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "port.build_train_df('2015-01-01').values[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# port.build_test_df('2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Portfolio' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-19ec98bb8ac4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AAPL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Portfolio' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "port['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
